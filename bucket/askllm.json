{
    "version": "0.0.9",
    "architecture": {
        "32bit": {
            "url": "https://github.com/robinmin/askllm/releases/download/v0.0.9/askllm_Windows_i386.zip",
            "bin": [
                "askllm.exe"
            ],
            "hash": "ba4a9a38360be03c331a82ce43ee23528910d05d19886725bb575623eca045ac"
        },
        "64bit": {
            "url": "https://github.com/robinmin/askllm/releases/download/v0.0.9/askllm_Windows_x86_64.zip",
            "bin": [
                "askllm.exe"
            ],
            "hash": "adaea34850d281beb45318600849658edbe4dd83002fedcd821f58ac9d782f24"
        },
        "arm64": {
            "url": "https://github.com/robinmin/askllm/releases/download/v0.0.9/askllm_Windows_arm64.zip",
            "bin": [
                "askllm.exe"
            ],
            "hash": "2e51f38ad074b7323c621fbc3b9f68b1643f941fc46bef434264bb8c2046cfc5"
        }
    },
    "homepage": "https://github.com/robinmin/askllm",
    "license": "Apache License 2.0",
    "description": "Askllm is a tiny command line tool for you to execute LLM inquiry with prompt or prompt file."
}